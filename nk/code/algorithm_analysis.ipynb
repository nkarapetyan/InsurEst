{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from math import log\n",
    "import numpy as np\n",
    "from array import array\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "policy_ID = 'PolicyNo' # name of the first column for identifying the policies\n",
    "\n",
    "sampling_data = '../../data/cleaned_training_data_2016_ver_02.csv'\n",
    "\n",
    "train_data = ''\n",
    "test_data = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here features and targets are defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = ['Driver_Total', 'Driver_Total_Male', 'Driver_Total_Female', 'Driver_Total_Single', 'Driver_Total_Married','Driver_Minimum_Age', 'Driver_Maximum_Age', 'Driver_Total_Teenager_Age_15_19', 'Driver_Total_College_Ages_20_23', 'Driver_Total_Young_Adult_Ages_24_29', 'Annual_Premium']#, 'Driver_Total_Low_Middle_Adult_Ages_30_39', 'Driver_Total_Middle_Adult_Ages_40_49', 'Driver_Total_Adult_Ages_50_64', 'Driver_Total_Senior_Ages_65_69', 'Driver_Total_Upper_Senior_Ages_70_plus']\n",
    "annual_prem_ftr = ['Annual_Premium']\n",
    "all_target = ['Claim_Count', 'Loss_Amount', 'Frequency', 'Severity', 'Loss_Ratio']\n",
    "#target_2 = ['Loss_Ratio']\n",
    "target_2 = ['Claim_Count']\n",
    "\n",
    "df = pd.read_csv(sampling_data)\n",
    "df = df.drop(policy_ID, 1)\n",
    "#data_sample = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This part takes out outliers based on Loss_Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df = df[df['Loss_Amount'] < 10000]\n",
    "\n",
    "#df = df[df['Loss_Ratio'] == 0]\n",
    "#df.shape\n",
    "#complete_data_frame = df\n",
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(424422, 68)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = df.take(np.random.permutation(len(df))[:1000])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data,test_data = train_test_split(df, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Driver_Total' 'Driver_Total_Male' 'Driver_Total_Female'\n",
      " 'Driver_Total_Single' 'Driver_Total_Married' 'Driver_Minimum_Age'\n",
      " 'Driver_Maximum_Age' 'Driver_Total_Teenager_Age_15_19'\n",
      " 'Driver_Total_College_Ages_20_23' 'Driver_Total_Young_Adult_Ages_24_29'\n",
      " 'Annual_Premium']\n"
     ]
    }
   ],
   "source": [
    "X_test = test_data[features]\n",
    "print X_test.columns.values\n",
    "y_test = test_data[target_2]\n",
    "X = train_data[features].values\n",
    "y = train_data[target_2].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1. Ordinary Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.20\n",
      "Variance score: 0.09\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.01284392, -0.0086026 , -0.00424132, -0.05215819, -0.03801597,\n",
       "        -0.00293223,  0.00215154, -0.05000768, -0.02635404, -0.01584545,\n",
       "         0.00019298]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X,y)\n",
    "rmse = math.sqrt(mean_squared_error(y_test, regr.predict(X_test))) # y_test -> true, X_test <- predicted\n",
    "print('RMSE: %.2f' % rmse)\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % regr.score(X_test, y_test))\n",
    "regr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.20\n",
      "Variance score: 0.09\n",
      "[[-0.01297316 -0.00869651 -0.00427665 -0.05183211 -0.03769617 -0.00290703\n",
      "   0.00213815 -0.04852688 -0.02569353 -0.01547767  0.00019269]]\n",
      "[ 0.08989663]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "regr = linear_model.Ridge (alpha = .5)\n",
    "regr.fit(X, y) \n",
    "\n",
    "rmse = math.sqrt(mean_squared_error(y_test, regr.predict(X_test))) # y_test -> true, X_test <- predicted\n",
    "print('RMSE: %.2f' % rmse)\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % regr.score(X_test, y_test))\n",
    "\n",
    "print regr.coef_\n",
    "\n",
    "print regr.intercept_ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.20\n",
      "Variance score: 0.09\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.Lasso(alpha = 0.1)\n",
    "reg.fit(X, y)\n",
    "\n",
    "rmse = math.sqrt(mean_squared_error(y_test, regr.predict(X_test))) # y_test -> true, X_test <- predicted\n",
    "print('RMSE: %.2f' % rmse)\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % regr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.4. Bayesian Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.20\n",
      "Variance score: 0.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.01297316, -0.00869651, -0.00427665, -0.05183211, -0.03769617,\n",
       "        -0.00290703,  0.00213815, -0.04852688, -0.02569353, -0.01547767,\n",
       "         0.00019269]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.BayesianRidge()\n",
    "y = train_data[target_2].values\n",
    "reg.fit(X,y)\n",
    "rmse = math.sqrt(mean_squared_error(y_test, regr.predict(X_test))) # y_test -> true, X_test <- predicted\n",
    "print('RMSE: %.2f' % rmse)\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % regr.score(X_test, y_test))\n",
    "regr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Combined Models\n",
    "### 1.1. Gradient Boosting Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_features = list(set(list(df.columns.values)) - set(all_target))\n",
    "X_test = test_data[features]\n",
    "y_test = test_data[target_2]\n",
    "X = train_data[features].values\n",
    "y = train_data[target_2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.datasets import make_friedman1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {'n_estimators': 100, 'max_depth': 4, 'min_samples_split': 2,\n",
    "          'learning_rate': 0.01, 'loss': 'ls'}\n",
    "clf = GradientBoostingRegressor(**params)\n",
    "\n",
    "clf.fit(X, y.ravel())\n",
    "rmse = math.sqrt(mean_squared_error(y_test, clf.predict(X_test))) # y_test -> true, X_test <- predicted\n",
    "print('RMSE: %.2f' % rmse)\n",
    "#clf.train_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = train_data[all_features]\n",
    "X = X.select_dtypes(exclude=['object'])\n",
    "\n",
    "clf = GradientBoostingRegressor(n_estimators=10, learning_rate=1.0).fit(X, y)\n",
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Plot feature importance \n",
    "feature_importance = clf.feature_importances_\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "print type(feature_importance)\n",
    "feature_importance = feature_importance[feature_importance>10]\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with important features as identified by gbr algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = list(X.columns[sorted_idx])\n",
    "print features\n",
    "X_test = test_data[features].values\n",
    "y_test = test_data[target_1].values\n",
    "X_train = train_data[features].values\n",
    "y_train = train_data[target_1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {'n_estimators': 200, 'max_depth': 4, 'min_samples_split': 2,\n",
    "          'learning_rate': 0.01, 'loss': 'ls'}\n",
    "clf = GradientBoostingRegressor(**params)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "rmse = math.sqrt(mean_squared_error(y_test, clf.predict(X_test))) # y_test -> true, X_test <- predicted\n",
    "print('RMSE: %.2f' % rmse)\n",
    "clf.train_score_.mean()\n",
    "clf.score(X_test, y_test)\n",
    "#from sklearn import metrics\n",
    "#metrics.accuracy_score(y_train, Predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = list(X.columns[sorted_idx])\n",
    "print features\n",
    "X_test = test_data[features].values\n",
    "y_test = test_data[target_1].values\n",
    "X_train = train_data[features].values\n",
    "y_train = train_data[target_1].values\n",
    "from sklearn import linear_model\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train,y_train)\n",
    "rmse = math.sqrt(mean_squared_error(y_test, regr.predict(X_test))) # y_test -> true, X_test <- predicted\n",
    "print('RMSE: %.2f' % rmse)\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % regr.score(X_test, y_test))\n",
    "regr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
