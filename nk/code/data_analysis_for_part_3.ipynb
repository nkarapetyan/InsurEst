{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Import of used libraries and declaration of the variables that will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from math import log\n",
    "import numpy as np\n",
    "from array import array\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "policy_ID = 'PolicyNo' # name of the first column for identifying the policies\n",
    "\n",
    "data_part_3_dir = '../data_part_3/'\n",
    "complete_train_data_file = '../data/training_data_2016.csv'\n",
    "\n",
    "raw_part_3_train_data_file = 'data_part_3.csv'\n",
    "raw_target_data_file = 'target_data_2016.csv'\n",
    "\n",
    "\n",
    "raw_part_3_data_file_with_target = \"part_3_with_target.csv\"\n",
    "\n",
    "attribute_names_file = 'cols_part_3.csv' # the columns for part_3\n",
    "target_names_file = 'target_cols.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Saving the required portion of the data specified by names of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_frame = pd.read_csv(complete_train_data_file) # reading complete data\n",
    "#train_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(424431, 25)\n"
     ]
    }
   ],
   "source": [
    "# read the attribute names in \\var keep_cols list\n",
    "with open(data_part_3_dir + attribute_names_file) as f:\n",
    "        keep_cols = f.read().splitlines()\n",
    "        \n",
    "train_data_part_3_frame = train_data_frame[keep_cols]\n",
    "train_data_part_3_frame.to_csv(data_part_3_dir + raw_part_3_train_data_file, index=False)\n",
    "print train_data_part_3_frame.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Checking the frequency of train data_part_3 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col_name in keep_cols:\n",
    "    if (col_name == policy_ID):\n",
    "        continue\n",
    "    test = train_data_frame.groupby(col_name)\n",
    "    #print test.size()  #<- uncomment for viewing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Saving target columns with PolicyNo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read the target names in \\var keep_cols list\n",
    "with open(data_part_3_dir + target_names_file) as f:\n",
    "        target_cols = f.read().splitlines()\n",
    "\n",
    "target_data_frame = train_data_frame[target_cols]\n",
    "target_data_frame.to_csv(data_part_3_dir + raw_target_data_file, index=False)\n",
    "#print target_data_frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Checking the frequency of target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col_name in target_cols:\n",
    "    test = target_data_frame.groupby(col_name)\n",
    "    \n",
    "    if (col_name == policy_ID):\n",
    "        #t = target_data_frame[col_name] # just to check if ID's are all unique\n",
    "        #print t.nunique() == len(t)     # just to check if ID's are all unique\n",
    "        continue\n",
    "    t= test.size()\n",
    "    #print t #<- uncomment for viewing results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3. Check if there are dublicates\n",
    "#### 3.1. Read the training part_3 and target together in the same data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#keep_cols.remove(policy_ID)\n",
    "#target_cols.remove(policy_ID)\n",
    "\n",
    "#cols = keep_cols + target_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Remove all dublicates from the complete raw training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424422\n",
      "424431\n"
     ]
    }
   ],
   "source": [
    "df = train_data_frame\n",
    "#df = df.drop(policy_ID, 1) # will drop the policyID column from the dataframe\n",
    "cols = list(df.columns.values) # the argument return the header\n",
    "cols.remove(policy_ID)\n",
    "rem_dup=df.drop_duplicates(cols)\n",
    "\n",
    "print len(rem_dup)\n",
    "print len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Translating Categorical Variables into Numerical\n",
    "#### 4.1. Testing how to access columns and rows and how to detect type of elements and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "0         Farm    \n",
      "1         Farm    \n",
      "2         Pleasure\n",
      "3         Pleasure\n",
      "4         Pleasure\n",
      "5         Work    \n",
      "6         Pleasure\n",
      "7         Farm    \n",
      "8         Farm    \n",
      "9         Pleasure\n",
      "10        Work    \n",
      "11        Pleasure\n",
      "12        Pleasure\n",
      "13        Farm    \n",
      "14        Farm    \n",
      "15        Farm    \n",
      "16        Farm    \n",
      "17        Pleasure\n",
      "18        Pleasure\n",
      "19        Pleasure\n",
      "20        Pleasure\n",
      "21        Pleasure\n",
      "22        Pleasure\n",
      "23        Farm    \n",
      "24        Pleasure\n",
      "25        Farm    \n",
      "26        Pleasure\n",
      "27        Work    \n",
      "28        Work    \n",
      "29        Work    \n",
      "            ...   \n",
      "424401    Work    \n",
      "424402    Pleasure\n",
      "424403    Pleasure\n",
      "424404    Pleasure\n",
      "424405    Work    \n",
      "424406    Work    \n",
      "424407    Pleasure\n",
      "424408    Work    \n",
      "424409    Pleasure\n",
      "424410    Work    \n",
      "424411    Work    \n",
      "424412    Pleasure\n",
      "424413    Work    \n",
      "424414    Work    \n",
      "424415    Pleasure\n",
      "424416    Pleasure\n",
      "424417    Pleasure\n",
      "424418    Pleasure\n",
      "424419    Pleasure\n",
      "424420    Work    \n",
      "424421    Work    \n",
      "424422    Farm    \n",
      "424423    Pleasure\n",
      "424424    Work    \n",
      "424425    Work    \n",
      "424426    Pleasure\n",
      "424427    Pleasure\n",
      "424428    Pleasure\n",
      "424429    Pleasure\n",
      "424430    Work    \n",
      "Name: Vehicle_Usage, dtype: object\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Farm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-8f5786b52ec3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# access the column 'other'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# access the element in column 'other' and row 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFarm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Farm' is not defined"
     ]
    }
   ],
   "source": [
    "other = 'Vehicle_Usage'\n",
    "print df['Vehicle_Annual_Miles'].dtype\n",
    "print df[other] # access the column 'other'\n",
    "df[other].iloc[3] # access the element in column 'other' and row 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'str'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "make_numeric() got an unexpected keyword argument 'axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2bb6246ef241>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mglob_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_numeric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#axis=0 defines that function is to be applied on each column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;31m#print df[col]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2290\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2291\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2292\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2294\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/src/inference.pyx\u001b[0m in \u001b[0;36mpandas.lib.map_infer (pandas/lib.c:65579)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2279\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mufunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2280\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2282\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: make_numeric() got an unexpected keyword argument 'axis'"
     ]
    }
   ],
   "source": [
    "glob_list = []\n",
    "def make_numeric(el):\n",
    "    if(type(el) == str):\n",
    "        if(el in glob_list):\n",
    "            el = glob_list.index(el)\n",
    "        else:\n",
    "            glob_list.append(el)\n",
    "            el = glob_list.index(el)\n",
    "    return el\n",
    "            \n",
    "df = train_data_part_3_frame\n",
    "#print train_data_part_3_frame\n",
    "for col in df:\n",
    "    if (df[col].dtype == 'object'):\n",
    "        glob_list = []\n",
    "        df[col] = df[col].apply(make_numeric, axis=0) #axis=0 defines that function is to be applied on each column\n",
    "        #print df[col]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Save the transformed data into the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outFile = 'training_data_2016_nare.csv'\n",
    "df.to_csv(outFile, index=False)\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3. Checking Frequencies again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col_name in keep_cols:\n",
    "    test = df.groupby(col_name)\n",
    "    \n",
    "    if (col_name == policy_ID):\n",
    "        #t = target_data_frame[col_name] # just to check if ID's are all unique\n",
    "        #print t.nunique() == len(t)     # just to check if ID's are all unique\n",
    "        continue\n",
    "    t= test.size()\n",
    "    print t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 5. Plotting some scatterplots\n",
    "#### 5.1. plotting function takes dataframe and the columns for x and y axises "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scatter_plot(data, x, y):\n",
    "    f = plt.figure()\n",
    "    ax = f.add_subplot(1, 1, 1)\n",
    "    ax.scatter(data[x], data[y])\n",
    "    plt.title(x + ' and ' + y + ' distribution')\n",
    "    plt.xlabel(x)\n",
    "    plt.ylabel(y)\n",
    "    #plt.show()\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: must be added \n",
    "col_y = 'Loss_Ration'\n",
    "col_x = ''\n",
    "#scatter_plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
